{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BlenderBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UahVKS1KXfID"
      },
      "source": [
        "#BlenderBot\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfyr3uiUtkoJ"
      },
      "source": [
        "# https://colab.research.google.com/drive/1CFTETc2DM59EFhDvU-iTR9MjsHbOBSyZ?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d3AfX0Do8BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2358e4-8005-476d-a7cb-c281076814c0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov  5 11:11:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPmSE5bDhaWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9c1f7f-c460-43e4-c809-00a003963c74"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ParlAI'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 35998 (delta 34), reused 42 (delta 16), pack-reused 35928\u001b[K\n",
            "Receiving objects: 100% (35998/35998), 63.98 MiB | 23.92 MiB/s, done.\n",
            "Resolving deltas: 100% (25495/25495), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFMx_kohwC7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7143a3a4-370c-4135-9a44-f7af0c2f2567"
      },
      "source": [
        "cd ParlAI/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ParlAI/ParlAI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m1YoG7VwDbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e1c698-7772-467f-b55a-7a3b4adb1655"
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating parlai.egg-info\n",
            "writing parlai.egg-info/PKG-INFO\n",
            "writing dependency_links to parlai.egg-info/dependency_links.txt\n",
            "writing entry points to parlai.egg-info/entry_points.txt\n",
            "writing requirements to parlai.egg-info/requires.txt\n",
            "writing top-level names to parlai.egg-info/top_level.txt\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/parlai.egg-link (link to .)\n",
            "Removing parlai 0.9.4 from easy-install.pth file\n",
            "Adding parlai 0.9.4 to easy-install.pth file\n",
            "Installing parlai script to /usr/local/bin\n",
            "\n",
            "Installed /content/ParlAI/ParlAI\n",
            "Processing dependencies for parlai==0.9.4\n",
            "error: Sphinx 1.8.5 is installed but Sphinx>=3.0 is required by {'sphinx-autodoc-typehints'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flvyweIpwE4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4e5173-762e-42a2-846f-5907d10a5b5d"
      },
      "source": [
        "!pip install 'git+https://github.com/rsennrich/subword-nmt.git#egg=subword-nmt'\n",
        "!pip install fvcore==0.1.1.post20200716"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: subword-nmt from git+https://github.com/rsennrich/subword-nmt.git#egg=subword-nmt in /usr/local/lib/python3.6/dist-packages/subword_nmt-0.3.7-py3.6.egg (0.3.7)\n",
            "Collecting fvcore==0.1.1.post20200716\n",
            "  Downloading https://files.pythonhosted.org/packages/81/ee/3709513b414c2b525e4f03c45215579f93f41dba797f0e5fe539e6bc92b7/fvcore-0.1.1.post20200716.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1.post20200716) (1.18.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1.post20200716) (4.41.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1.post20200716) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1.post20200716) (7.0.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1.post20200716) (0.8.7)\n",
            "Building wheels for collected packages: fvcore, pyyaml\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post20200716-cp36-none-any.whl size=42325 sha256=d4779705884ff4eff6fd231dd2e06126d01f65180fc800b4c4d7eeaebd7bb229\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/99/f4/42a6bef61c07b3d78dfe6d7ebff259444c4526504cf72378d7\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=5044bed01df24095c0c48f6d6bb3e940c7594e4687183bdb71011409260f3b9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built fvcore pyyaml\n",
            "\u001b[31mERROR: myst-parser 0.12.10 requires markdown-it-py~=0.5.4, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: hydra-core 1.0.3 requires antlr4-python3-runtime==4.8, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: myst-parser 0.12.10 has requirement sphinx<4,>=2, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: parlai 0.9.4 has requirement attrs~=19.3, but you'll have attrs 20.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: parlai 0.9.4 has requirement torchtext>=0.5.0, but you'll have torchtext 0.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml, yacs, portalocker, fvcore\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: fvcore 0.1.2.post20201104\n",
            "    Uninstalling fvcore-0.1.2.post20201104:\n",
            "      Successfully uninstalled fvcore-0.1.2.post20201104\n",
            "Successfully installed fvcore-0.1.1.post20200716 portalocker-2.0.0 pyyaml-5.3.1 yacs-0.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdC8nvnLY_Lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42eda3c0-b009-4fe3-b1ae-480f53d8ddce"
      },
      "source": [
        "!python /content/ParlAI/parlai/scripts/interactive.py -t blended_skill_talk -mf zoo:blender/blender_3B/model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                 /@&%###%&&@@#\n",
            "                      .,*/((((##@@@&%%#%%&&@@@&%%#/*.\n",
            "             #@@&&&%%%%##(((///*****//(((###%%%&&&@@@@@&&%#%%#.\n",
            "         .%&@@@@@&&&%%%####((((////((((####%%%&&&@@@@@&&%%#%%####,\n",
            "           ./,,#(//**,,.....,,,,***////((((########%%%%%%%%###(((\n",
            "              /*(//**,,,....,,,,***////((((########%%%%%%%%###(#%*\n",
            "               (*,...      ...,,,***//////((((((///////(/*...,/#@@@(\n",
            "               **,,..         ...,,,,,,,,,,........,,*///*...*(#@@@@&&*\n",
            "               ./,,..          ...,,,,,,,,,........,,*//*,...*#/,,,,,/%#\n",
            "                (*,..          ...,,,,,,,,,........,,*//*,..,/(      .,#(\n",
            "                **,..          ...,,,,,,,,,.........,*//*,..,((       .,(#\n",
            "                 /*,..          ....,,,,,,,.....  ..,***,,,,(#         ..#&\n",
            "                 **,..          ....,,,,,,,....   ..,***,,,*#.         .,%@\n",
            "                 ./,...       B l e n d e r B o t ...***,,,*#          .*%@\n",
            "                  /*,..          ...,,,,,,,....    .,**,,,,/#         ..(%/\n",
            "                  /*,,..         ...,,,,,,,...    ..,*,,,,,(.         ..#&\n",
            "                  ,/*,..         ...,,,,,,,...    ..,*,,,,*#         ..*%(\n",
            "                   /*,..         ...,,,,,.....    ..,*,*,,/(         ..#&\n",
            "                   /**,..        ...,,,,.....    ...,***,*(.       ,,(%.\n",
            "                    (/*,,..      ....,,.....     ...,****(&@@@&&&#,\n",
            "                     (/*,,...   .....,,......     ..,****#@,\n",
            "                     *(/*,,/....*(###%(,(%%##(*.  ./,,**(\n",
            "                      ,//**(,........,/((#.........*,**(\n",
            "                      .(#//*,,,,,,.*.,/((%/,,.....,,*/@\n",
            "                    ((######//****,/.,/(#%#***,***(&@@@@@(\n",
            "                   *&%%#####%%%%%%%#//(#%&%%&&@@@@@@@@@@@@*\n",
            "                   &&%%%###((((((####%%%%&&&&&@@@@@@@@@@&&@.\n",
            "                  *##%%%##(((((((####%%%%%&&&&@@@@@@@@@&#/*,\n",
            "                 .(##%#/,  .,*((##%%%&&&&%%%#####%&&@&&%#(/*.\n",
            "                 /(###(,   .,*/(##%%%&&&&%%%######%&&&&%#(/*,\n",
            "                */((((*.  ..,//((##%%%%%%%%#######%&&&&%%#(/*,\n",
            "               .//(((/,   .,*//((###%%%%%%########%%&&&%%#((/,.\n",
            "              .&####(((((((((######%%%%%%%%&&&&&&&@@@@@@@@@@@@@#\n",
            "               *&#.   .*/((((#######%%%%%%&&&&&&&@@@@@#/.   (&/\n",
            "11:12:22 INFO | building data: /content/ParlAI/ParlAI/data/models/blender/blender_3B/BST3B.tgz\n",
            "11:12:22 INFO | Downloading http://parl.ai/downloads/_models/blender/BST3B.tgz to /content/ParlAI/ParlAI/data/models/blender/blender_3B/BST3B.tgz\n",
            "Downloading BST3B.tgz: 100% 4.95G/4.95G [03:20<00:00, 24.7MB/s]\n",
            "11:18:08 WARN | Overriding opt[\"task\"] to blended_skill_talk (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2:normalized,empathetic_dialogues)\n",
            "11:18:08 WARN | Overriding opt[\"model_file\"] to /content/ParlAI/ParlAI/data/models/blender/blender_3B/model (previously: /checkpoint/edinan/20200331/finetune_bst_gen_baseline_convai2_normal/de6/model)\n",
            "11:18:08 WARN | Loading model with `--beam-block-full-context false`\n",
            "11:18:13 INFO | Using CUDA\n",
            "11:18:13 INFO | loading dictionary from /content/ParlAI/ParlAI/data/models/blender/blender_3B/model.dict\n",
            "11:18:13 INFO | num words = 8008\n",
            "11:18:15 INFO | TransformerGenerator: full interactive mode on.\n",
            "11:19:19 INFO | Total parameters: 2,696,268,800 (2,695,613,440 trainable)\n",
            "11:19:19 INFO | Loading existing model params from /content/ParlAI/ParlAI/data/models/blender/blender_3B/model\n",
            "11:21:49 INFO | Opt:\n",
            "11:21:49 INFO |     activation: gelu\n",
            "11:21:49 INFO |     adafactor_eps: '[1e-30, 0.001]'\n",
            "11:21:49 INFO |     adam_eps: 1e-08\n",
            "11:21:49 INFO |     add_p1_after_newln: False\n",
            "11:21:49 INFO |     aggregate_micro: False\n",
            "11:21:49 INFO |     allow_missing_init_opts: False\n",
            "11:21:49 INFO |     attention_dropout: 0.0\n",
            "11:21:49 INFO |     batchsize: 128\n",
            "11:21:49 INFO |     beam_block_full_context: False\n",
            "11:21:49 INFO |     beam_block_list_filename: None\n",
            "11:21:49 INFO |     beam_block_ngram: 3\n",
            "11:21:49 INFO |     beam_context_block_ngram: 3\n",
            "11:21:49 INFO |     beam_delay: 30\n",
            "11:21:49 INFO |     beam_length_penalty: 0.65\n",
            "11:21:49 INFO |     beam_min_length: 20\n",
            "11:21:49 INFO |     beam_size: 10\n",
            "11:21:49 INFO |     betas: '[0.9, 0.999]'\n",
            "11:21:49 INFO |     bpe_add_prefix_space: True\n",
            "11:21:49 INFO |     bpe_debug: False\n",
            "11:21:49 INFO |     bpe_merge: /content/ParlAI/ParlAI/data/models/blender/blender_3B/model.dict-merges.txt\n",
            "11:21:49 INFO |     bpe_vocab: /content/ParlAI/ParlAI/data/models/blender/blender_3B/model.dict-vocab.json\n",
            "11:21:49 INFO |     compute_tokenized_bleu: False\n",
            "11:21:49 INFO |     datapath: /content/ParlAI/ParlAI/data\n",
            "11:21:49 INFO |     datatype: train\n",
            "11:21:49 INFO |     delimiter: '  '\n",
            "11:21:49 INFO |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "11:21:49 INFO |     dict_endtoken: __end__\n",
            "11:21:49 INFO |     dict_file: /content/ParlAI/ParlAI/data/models/blender/blender_3B/model.dict\n",
            "11:21:49 INFO |     dict_include_test: False\n",
            "11:21:49 INFO |     dict_include_valid: False\n",
            "11:21:49 INFO |     dict_initpath: None\n",
            "11:21:49 INFO |     dict_language: english\n",
            "11:21:49 INFO |     dict_loaded: True\n",
            "11:21:49 INFO |     dict_lower: False\n",
            "11:21:49 INFO |     dict_max_ngram_size: -1\n",
            "11:21:49 INFO |     dict_maxexs: -1\n",
            "11:21:49 INFO |     dict_maxtokens: -1\n",
            "11:21:49 INFO |     dict_minfreq: 0\n",
            "11:21:49 INFO |     dict_nulltoken: __null__\n",
            "11:21:49 INFO |     dict_starttoken: __start__\n",
            "11:21:49 INFO |     dict_textfields: text,labels\n",
            "11:21:49 INFO |     dict_tokenizer: bytelevelbpe\n",
            "11:21:49 INFO |     dict_unktoken: __unk__\n",
            "11:21:49 INFO |     display_add_fields: \n",
            "11:21:49 INFO |     display_examples: False\n",
            "11:21:49 INFO |     display_partner_persona: True\n",
            "11:21:49 INFO |     display_prettify: False\n",
            "11:21:49 INFO |     download_path: None\n",
            "11:21:49 INFO |     dropout: 0.1\n",
            "11:21:49 INFO |     dynamic_batching: None\n",
            "11:21:49 INFO |     embedding_projection: random\n",
            "11:21:49 INFO |     embedding_size: 2560\n",
            "11:21:49 INFO |     embedding_type: random\n",
            "11:21:49 INFO |     embeddings_scale: True\n",
            "11:21:49 INFO |     eval_batchsize: None\n",
            "11:21:49 INFO |     evaltask: None\n",
            "11:21:49 INFO |     ffn_size: 10240\n",
            "11:21:49 INFO |     force_fp16_tokens: True\n",
            "11:21:49 INFO |     fp16: True\n",
            "11:21:49 INFO |     fp16_impl: mem_efficient\n",
            "11:21:49 INFO |     gpu: -1\n",
            "11:21:49 INFO |     gradient_clip: 0.1\n",
            "11:21:49 INFO |     hf_skip_special_tokens: True\n",
            "11:21:49 INFO |     hide_labels: False\n",
            "11:21:49 INFO |     history_add_global_end_token: end\n",
            "11:21:49 INFO |     history_reversed: False\n",
            "11:21:49 INFO |     history_size: -1\n",
            "11:21:49 INFO |     image_cropsize: 224\n",
            "11:21:49 INFO |     image_mode: raw\n",
            "11:21:49 INFO |     image_size: 256\n",
            "11:21:49 INFO |     include_checked_sentence: True\n",
            "11:21:49 INFO |     include_initial_utterances: False\n",
            "11:21:49 INFO |     include_knowledge: True\n",
            "11:21:49 INFO |     include_knowledge_separator: False\n",
            "11:21:49 INFO |     include_personas: True\n",
            "11:21:49 INFO |     inference: beam\n",
            "11:21:49 INFO |     init_model: /checkpoint/parlai/zoo/meena/20200319_meenav0data_tall_2.7B_adamoptimizer/20200319_13.3ppl_200kupdates/model\n",
            "11:21:49 INFO |     init_opt: None\n",
            "11:21:49 INFO |     interactive_mode: True\n",
            "11:21:49 INFO |     interactive_task: True\n",
            "11:21:49 INFO |     invsqrt_lr_decay_gamma: -1\n",
            "11:21:49 INFO |     label_truncate: 128\n",
            "11:21:49 INFO |     label_type: response\n",
            "11:21:49 INFO |     learn_positional_embeddings: False\n",
            "11:21:49 INFO |     learningrate: 7e-06\n",
            "11:21:49 INFO |     local_human_candidates_file: None\n",
            "11:21:49 INFO |     log_every_n_secs: 10.0\n",
            "11:21:49 INFO |     log_keep_fields: all\n",
            "11:21:49 INFO |     loglevel: info\n",
            "11:21:49 INFO |     lr_scheduler: reduceonplateau\n",
            "11:21:49 INFO |     lr_scheduler_decay: 0.5\n",
            "11:21:49 INFO |     lr_scheduler_patience: 3\n",
            "11:21:49 INFO |     max_lr_steps: -1\n",
            "11:21:49 INFO |     max_train_time: 27647.999999999996\n",
            "11:21:49 INFO |     metrics: default\n",
            "11:21:49 INFO |     model: transformer/generator\n",
            "11:21:49 INFO |     model_file: /content/ParlAI/ParlAI/data/models/blender/blender_3B/model\n",
            "11:21:49 INFO |     model_parallel: True\n",
            "11:21:49 INFO |     momentum: 0\n",
            "11:21:49 INFO |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "11:21:49 INFO |     n_decoder_layers: 24\n",
            "11:21:49 INFO |     n_encoder_layers: 2\n",
            "11:21:49 INFO |     n_heads: 32\n",
            "11:21:49 INFO |     n_layers: 2\n",
            "11:21:49 INFO |     n_positions: 128\n",
            "11:21:49 INFO |     n_segments: 0\n",
            "11:21:49 INFO |     nesterov: True\n",
            "11:21:49 INFO |     no_cuda: False\n",
            "11:21:49 INFO |     num_epochs: -1\n",
            "11:21:49 INFO |     num_topics: 5\n",
            "11:21:49 INFO |     numthreads: 1\n",
            "11:21:49 INFO |     nus: [0.7]\n",
            "11:21:49 INFO |     optimizer: mem_eff_adam\n",
            "11:21:49 INFO |     outfile: \n",
            "11:21:49 INFO |     output_scaling: 1.0\n",
            "11:21:49 INFO |     override: \"{'task': 'blended_skill_talk', 'model_file': '/content/ParlAI/ParlAI/data/models/blender/blender_3B/model'}\"\n",
            "11:21:49 INFO |     parlai_home: /checkpoint/edinan/20200331/finetune_bst_gen_baseline_convai2_normal/ParlAI\n",
            "11:21:49 INFO |     person_tokens: False\n",
            "11:21:49 INFO |     rank_candidates: False\n",
            "11:21:49 INFO |     relu_dropout: 0.0\n",
            "11:21:49 INFO |     remove_political_convos: False\n",
            "11:21:49 INFO |     safe_personas_only: True\n",
            "11:21:49 INFO |     save_after_valid: True\n",
            "11:21:49 INFO |     save_every_n_secs: -1\n",
            "11:21:49 INFO |     save_format: conversations\n",
            "11:21:49 INFO |     share_word_embeddings: True\n",
            "11:21:49 INFO |     short_final_eval: False\n",
            "11:21:49 INFO |     show_advanced_args: False\n",
            "11:21:49 INFO |     single_turn: False\n",
            "11:21:49 INFO |     skip_generation: False\n",
            "11:21:49 INFO |     special_tok_lst: None\n",
            "11:21:49 INFO |     split_lines: False\n",
            "11:21:49 INFO |     starttime: Mar31_06-04\n",
            "11:21:49 INFO |     task: blended_skill_talk\n",
            "11:21:49 INFO |     temperature: 1.0\n",
            "11:21:49 INFO |     tensorboard_log: False\n",
            "11:21:49 INFO |     text_truncate: 128\n",
            "11:21:49 INFO |     topk: 10\n",
            "11:21:49 INFO |     topp: 0.9\n",
            "11:21:49 INFO |     train_experiencer_only: False\n",
            "11:21:49 INFO |     truncate: 128\n",
            "11:21:49 INFO |     update_freq: 2\n",
            "11:21:49 INFO |     use_reply: label\n",
            "11:21:49 INFO |     validation_cutoff: 1.0\n",
            "11:21:49 INFO |     validation_every_n_epochs: 0.25\n",
            "11:21:49 INFO |     validation_every_n_secs: -1\n",
            "11:21:49 INFO |     validation_max_exs: -1\n",
            "11:21:49 INFO |     validation_metric: ppl\n",
            "11:21:49 INFO |     validation_metric_mode: min\n",
            "11:21:49 INFO |     validation_patience: 10\n",
            "11:21:49 INFO |     validation_share_agent: False\n",
            "11:21:49 INFO |     variant: prelayernorm\n",
            "11:21:49 INFO |     verbose: False\n",
            "11:21:49 INFO |     warmup_rate: 0.0001\n",
            "11:21:49 INFO |     warmup_updates: 100\n",
            "11:21:49 INFO |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "11:21:49 INFO | creating task(s): blended_skill_talk\n",
            "[ loading personas.. ]\n",
            "\n",
            "  [NOTE: In the BST paper both partners have a persona.\n",
            "         You can choose to ignore yours, the model never sees it.\n",
            "         In the Blender paper, this was not used for humans.\n",
            "         You can also turn personas off with --include-personas False]\n",
            "\n",
            "[building data: /content/ParlAI/ParlAI/data/blended_skill_talk]\n",
            "11:21:49 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/blended_skill_talk.tar.gz to /content/ParlAI/ParlAI/data/blended_skill_talk/blended_skill_talk.tar.gz\n",
            "Downloading blended_skill_talk.tar.gz: 100% 38.1M/38.1M [00:03<00:00, 12.5MB/s]\n",
            "11:21:54 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/personas_list.txt to /content/ParlAI/ParlAI/data/blended_skill_talk/persona_list.txt\n",
            "Downloading persona_list.txt: 0.00B [00:01, ?B/s]\n",
            "11:21:56 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/topic_to_persona_list.txt to /content/ParlAI/ParlAI/data/blended_skill_talk/topic_to_persona_list.txt\n",
            "Downloading topic_to_persona_list.txt: 0.00B [00:00, ?B/s]\n",
            "11:21:57 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__train__both_sides.json to /content/ParlAI/ParlAI/data/blended_skill_talk/ed_persona_topicifier__train__both_sides.json\n",
            "Downloading ed_persona_topicifier__train__both_sides.json: 0.00B [00:02, ?B/s]\n",
            "11:22:00 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__train__experiencer_only.json to /content/ParlAI/ParlAI/data/blended_skill_talk/ed_persona_topicifier__train__experiencer_only.json\n",
            "Downloading ed_persona_topicifier__train__experiencer_only.json: 0.00B [00:02, ?B/s]\n",
            "11:22:02 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__valid__experiencer_only.json to /content/ParlAI/ParlAI/data/blended_skill_talk/ed_persona_topicifier__valid__experiencer_only.json\n",
            "Downloading ed_persona_topicifier__valid__experiencer_only.json: 0.00B [00:04, ?B/s]\n",
            "11:22:07 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__test__experiencer_only.json to /content/ParlAI/ParlAI/data/blended_skill_talk/ed_persona_topicifier__test__experiencer_only.json\n",
            "Downloading ed_persona_topicifier__test__experiencer_only.json: 0.00B [00:04, ?B/s]\n",
            "11:22:11 INFO | Downloading http://parl.ai/downloads/blended_skill_talk/safe_personas_2.txt to /content/ParlAI/ParlAI/data/blended_skill_talk/safe_personas.txt\n",
            "Downloading safe_personas.txt: 0.00B [00:01, ?B/s]\n",
            "Loading /content/ParlAI/ParlAI/data/blended_skill_talk/train.json.\n",
            "Saving to /content/ParlAI/ParlAI/data/blended_skill_talk/train.txt\n",
            "Loading /content/ParlAI/ParlAI/data/blended_skill_talk/valid.json.\n",
            "Saving to /content/ParlAI/ParlAI/data/blended_skill_talk/valid.txt\n",
            "Loading /content/ParlAI/ParlAI/data/blended_skill_talk/test.json.\n",
            "Saving to /content/ParlAI/ParlAI/data/blended_skill_talk/test.txt\n",
            "\u001b[0;34m[context]:\u001b[0;0m \u001b[1myour persona: i got married last year.\n",
            "your persona: i live on a boat.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLL55umFsHG8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}